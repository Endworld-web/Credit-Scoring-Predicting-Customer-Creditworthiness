{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0564d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>Debt</th>\n",
       "      <th>Credit_Score</th>\n",
       "      <th>Loan_Amount</th>\n",
       "      <th>Loan_Term</th>\n",
       "      <th>Num_Credit_Cards</th>\n",
       "      <th>Payment_History</th>\n",
       "      <th>Employment_Status</th>\n",
       "      <th>Residence_Type</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Creditworthiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>Female</td>\n",
       "      <td>Master</td>\n",
       "      <td>149406</td>\n",
       "      <td>34089</td>\n",
       "      <td>581</td>\n",
       "      <td>49200</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>Rented</td>\n",
       "      <td>Single</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>Female</td>\n",
       "      <td>High School</td>\n",
       "      <td>78896</td>\n",
       "      <td>8626</td>\n",
       "      <td>648</td>\n",
       "      <td>20147</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>Good</td>\n",
       "      <td>Employed</td>\n",
       "      <td>Mortgaged</td>\n",
       "      <td>Married</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>Female</td>\n",
       "      <td>Master</td>\n",
       "      <td>119339</td>\n",
       "      <td>46281</td>\n",
       "      <td>329</td>\n",
       "      <td>41307</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>Owned</td>\n",
       "      <td>Single</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>Male</td>\n",
       "      <td>High School</td>\n",
       "      <td>131067</td>\n",
       "      <td>29403</td>\n",
       "      <td>816</td>\n",
       "      <td>19019</td>\n",
       "      <td>60</td>\n",
       "      <td>8</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Employed</td>\n",
       "      <td>Owned</td>\n",
       "      <td>Single</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>Male</td>\n",
       "      <td>PhD</td>\n",
       "      <td>38001</td>\n",
       "      <td>30032</td>\n",
       "      <td>673</td>\n",
       "      <td>16317</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>Average</td>\n",
       "      <td>Employed</td>\n",
       "      <td>Rented</td>\n",
       "      <td>Married</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender    Education  Income   Debt  Credit_Score  Loan_Amount  \\\n",
       "0   56  Female       Master  149406  34089           581        49200   \n",
       "1   69  Female  High School   78896   8626           648        20147   \n",
       "2   46  Female       Master  119339  46281           329        41307   \n",
       "3   32    Male  High School  131067  29403           816        19019   \n",
       "4   60    Male          PhD   38001  30032           673        16317   \n",
       "\n",
       "   Loan_Term  Num_Credit_Cards Payment_History Employment_Status  \\\n",
       "0         60                 4             Bad        Unemployed   \n",
       "1         24                 7            Good          Employed   \n",
       "2         12                 8             Bad        Unemployed   \n",
       "3         60                 8             Bad          Employed   \n",
       "4         36                 4         Average          Employed   \n",
       "\n",
       "  Residence_Type Marital_Status  Creditworthiness  \n",
       "0         Rented         Single                 1  \n",
       "1      Mortgaged        Married                 1  \n",
       "2          Owned         Single                 1  \n",
       "3          Owned         Single                 1  \n",
       "4         Rented        Married                 0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49c729ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   Age  Gender    Education  Income   Debt  Credit_Score  Loan_Amount  \\\n",
       " 0   56  Female       Master  149406  34089           581        49200   \n",
       " 1   69  Female  High School   78896   8626           648        20147   \n",
       " 2   46  Female       Master  119339  46281           329        41307   \n",
       " 3   32    Male  High School  131067  29403           816        19019   \n",
       " 4   60    Male          PhD   38001  30032           673        16317   \n",
       " \n",
       "    Loan_Term  Num_Credit_Cards Payment_History Employment_Status  \\\n",
       " 0         60                 4             Bad        Unemployed   \n",
       " 1         24                 7            Good          Employed   \n",
       " 2         12                 8             Bad        Unemployed   \n",
       " 3         60                 8             Bad          Employed   \n",
       " 4         36                 4         Average          Employed   \n",
       " \n",
       "   Residence_Type Marital_Status  \n",
       " 0         Rented         Single  \n",
       " 1      Mortgaged        Married  \n",
       " 2          Owned         Single  \n",
       " 3          Owned         Single  \n",
       " 4         Rented        Married  ,\n",
       " 0    1\n",
       " 1    1\n",
       " 2    1\n",
       " 3    1\n",
       " 4    0\n",
       " Name: Creditworthiness, dtype: int64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_col = \"Creditworthiness\"\n",
    "feature_cols = [col for col in df.columns if col != target_col]\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df[target_col]\n",
    "\n",
    "X.head(), y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51666e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\"Age\", \"Income\", \"Debt\", \"Credit_Score\",\n",
    "                    \"Loan_Amount\", \"Loan_Term\", \"Num_Credit_Cards\"]\n",
    "categorical_features = [\"Gender\", \"Education\", \"Payment_History\",\n",
    "                        \"Employment_Status\", \"Residence_Type\", \"Marital_Status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "600cd019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9600, 13), (2400, 13))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c48d675",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_features),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "rf_clf = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocess),\n",
    "        (\"model\", RandomForestClassifier(\n",
    "            n_estimators=300,\n",
    "            max_depth=None,\n",
    "            n_jobs=-1,\n",
    "            class_weight=\"balanced_subsample\",\n",
    "            random_state=42,\n",
    "        )),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "131b0066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7020833333333333\n",
      "ROC-AUC: 0.49860650072603185\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.00      0.00       714\n",
      "           1       0.70      1.00      0.82      1686\n",
      "\n",
      "    accuracy                           0.70      2400\n",
      "   macro avg       0.52      0.50      0.41      2400\n",
      "weighted avg       0.59      0.70      0.58      2400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "y_proba = rf_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae0361ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Threshold = 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.00      0.00       714\n",
      "           1       0.70      1.00      0.82      1686\n",
      "\n",
      "    accuracy                           0.70      2400\n",
      "   macro avg       0.52      0.50      0.41      2400\n",
      "weighted avg       0.59      0.70      0.58      2400\n",
      "\n",
      "\n",
      "Threshold = 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       714\n",
      "           1       0.70      1.00      0.83      1686\n",
      "\n",
      "    accuracy                           0.70      2400\n",
      "   macro avg       0.35      0.50      0.41      2400\n",
      "weighted avg       0.49      0.70      0.58      2400\n",
      "\n",
      "\n",
      "Threshold = 0.3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       714\n",
      "           1       0.70      1.00      0.83      1686\n",
      "\n",
      "    accuracy                           0.70      2400\n",
      "   macro avg       0.35      0.50      0.41      2400\n",
      "weighted avg       0.49      0.70      0.58      2400\n",
      "\n",
      "\n",
      "Threshold = 0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       714\n",
      "           1       0.70      1.00      0.83      1686\n",
      "\n",
      "    accuracy                           0.70      2400\n",
      "   macro avg       0.35      0.50      0.41      2400\n",
      "weighted avg       0.49      0.70      0.58      2400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danil\\OneDrive\\Desktop\\Github\\ml-credit-scoring\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\danil\\OneDrive\\Desktop\\Github\\ml-credit-scoring\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\danil\\OneDrive\\Desktop\\Github\\ml-credit-scoring\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\danil\\OneDrive\\Desktop\\Github\\ml-credit-scoring\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\danil\\OneDrive\\Desktop\\Github\\ml-credit-scoring\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\danil\\OneDrive\\Desktop\\Github\\ml-credit-scoring\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\danil\\OneDrive\\Desktop\\Github\\ml-credit-scoring\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\danil\\OneDrive\\Desktop\\Github\\ml-credit-scoring\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\danil\\OneDrive\\Desktop\\Github\\ml-credit-scoring\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_proba = rf_clf.predict_proba(X_test)[:, 1]\n",
    "for thr in [0.5, 0.4, 0.3, 0.2]:\n",
    "    y_pred_thr = (y_proba > thr).astype(int)\n",
    "    print(f\"\\nThreshold = {thr}\")\n",
    "    print(classification_report(y_test, y_pred_thr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "031f2ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Creditworthiness\n",
       " 1    6745\n",
       " 0    2855\n",
       " Name: count, dtype: int64,\n",
       " Creditworthiness\n",
       " 1    0.702604\n",
       " 0    0.297396\n",
       " Name: proportion, dtype: float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(), y_train.value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa1e5449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.45      , 0.66666667, 0.70666667, 0.74333333, 0.77366667,\n",
       "       0.79016667, 0.82      ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_proba = rf_clf.predict_proba(X_test)[:, 1]\n",
    "np.percentile(y_proba, [0, 25, 50, 75, 90, 95, 99])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d640709",
   "metadata": {},
   "source": [
    "The RandomForest model assigns very similar and relatively high probabilities to almost all samples (0.45â€“0.82). As a result, the classifier effectively predicts only the majority class (1) for all test cases, leading to high accuracy but ROC-AUC close to 0.5 and zero recall for the minority class (0). This suggests that, given the current synthetic dataset and features, the model cannot meaningfully discriminate between creditworthy and non-creditworthy clients."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
